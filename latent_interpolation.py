import torch
from torchvision.utils import save_image
import numpy as np
from q1_train_vae import VAE

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load the trained model
model = torch.load('results/q1/model.pt', map_location=device)
model.eval()  # Set to evaluation mode

def generate_interpolations():
    """
    Generate and visualize interpolations between two random points in latent space
    and their corresponding pixel space interpolations.
    """
    with torch.no_grad():
        # Generate two random points in latent space
        z0 = torch.randn(1, 20).to(device)
        z1 = torch.randn(1, 20).to(device)
        
        # Generate the corresponding images
        x0 = model.decode(z0)
        x1 = model.decode(z1)
        
        # Create alpha values for interpolation
        alphas = torch.linspace(0, 1, 11)  # [0, 0.1, 0.2, ..., 1.0]
        
        # Initialize lists to store interpolated images
        latent_interpolations = []
        pixel_interpolations = []
        
        # Generate interpolations
        for alpha in alphas:
            # (a) Interpolation in latent space
            z_alpha = alpha * z0 + (1 - alpha) * z1
            x_alpha = model.decode(z_alpha)
            latent_interpolations.append(x_alpha.view(1, 28, 28))
            
            # (b) Interpolation in pixel space
            x_hat_alpha = alpha * x0 + (1 - alpha) * x1
            pixel_interpolations.append(x_hat_alpha.view(1, 28, 28))
        
        # Convert lists to tensors and reshape properly
        latent_interpolations = torch.cat(latent_interpolations, dim=0)
        pixel_interpolations = torch.cat(pixel_interpolations, dim=0)
        
        # Reshape to (num_images, channels, height, width)
        latent_interpolations = latent_interpolations.view(-1, 1, 28, 28)
        pixel_interpolations = pixel_interpolations.view(-1, 1, 28, 28)
        
        # Save the interpolations
        save_image(latent_interpolations, 'results/q1/q9_latent_interpolation.png', nrow=11, normalize=True)
        save_image(pixel_interpolations, 'results/q1/q9_pixel_interpolation.png', nrow=11, normalize=True)
        
        # Print analysis
        print("\nInterpolation Analysis:")
        print("---------------------")
        print("Two types of interpolations have been generated:")
        print("\n1. Latent Space Interpolation (q9_latent_interpolation.png):")
        print("   - Shows interpolation between z0 and z1 in the latent space")
        print("   - Each image is generated by decoding an interpolated latent vector")
        print("   - This shows how the VAE's learned manifold handles transitions")
        
        print("\n2. Pixel Space Interpolation (q9_pixel_interpolation.png):")
        print("   - Shows direct interpolation between the generated images x0 and x1")
        print("   - Each image is a linear combination of the pixel values")
        print("   - This serves as a baseline for comparison")
        
        print("\nCompare the two types of interpolations to see:")
        print("1. How smoothly the VAE transitions between digits")
        print("2. Whether the latent space interpolation produces more meaningful transitions")
        print("3. If the VAE has learned a well-structured latent space")

if __name__ == "__main__":
    print("Generating interpolations...")
    generate_interpolations()
    print("Interpolations saved to 'results/q1/q9_latent_interpolation.png' and 'results/q1/q9_pixel_interpolation.png'") 